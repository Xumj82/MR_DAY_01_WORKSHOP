{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Workshop] Textual Knowledge Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"ws_img_001.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Package Installation (one time job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#pip install -U spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    " #!pip install -U nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import nltk\n",
    "#nltk.download() # Select and Download the \"popular\" from \"Collections\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Text Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Lower casing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lower_casing(sentence):\n",
    "    # Quiz: How to implement this function without using str.lower()?\n",
    "    new_sentence = sentence.lower()\n",
    "    return new_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Abbreviation expansion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_abbriviation(sentence):\n",
    "    replacement_patterns = [\n",
    "        (r'won\\'t', 'will not'),\n",
    "        (r'can\\'t', 'cannot'),\n",
    "        (r'i\\'m', 'i am'),\n",
    "        (r'ain\\'t', 'is not'),\n",
    "        (r'(\\w+)\\'ll', '\\g<1> will'),\n",
    "        (r'(\\w+)n\\'t', '\\g<1> not'),\n",
    "        (r'(\\w+)\\'ve', '\\g<1> have'),\n",
    "        (r'(\\w+)\\'s', '\\g<1> is'),\n",
    "        (r'(\\w+)\\'re', '\\g<1> are'),\n",
    "        (r'(\\w+)\\'d', '\\g<1> would')]\n",
    "    patterns = [(re.compile(regex), repl) for (regex, repl) in replacement_patterns]\n",
    "\n",
    "    new_sentence = sentence\n",
    "    for (pattern, repl) in patterns:\n",
    "        (new_sentence, count) = re.subn(pattern, repl, new_sentence)\n",
    "    return new_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Punctuation removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def punctuation_removal(sentence):\n",
    "    # Remove the all the punctuations except '\n",
    "    new_sentence = re.sub(',|!|\\?|\\\"|<|>|\\(|\\)|\\[|\\]|\\{|\\}|@|#|\\+|\\=|\\-|\\_|~|\\&|\\*|\\^|%|\\||\\$|/|`|\\.|\\'',\n",
    "                          '', sentence,count=0, flags=0)\n",
    "    return new_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Sentence tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenization(sentence):\n",
    "    new_sentence = nltk.word_tokenize(sentence)\n",
    "    return new_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 Stopwords removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stopword_removal(sentence):\n",
    "    #stoplist = stopwords.words('english')\n",
    "     \n",
    "    with open('./stopwords.txt') as file:\n",
    "        stoplist = [stopword.replace('\\n', '').lower() for stopword in file.readlines()]\n",
    "    \n",
    "    new_sentence = [word for word in sentence if word not in stoplist]\n",
    "    return new_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6 Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos(word):\n",
    "    pack = nltk.pos_tag([word])\n",
    "    tag = pack[0][1]\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "def lemmatization(sentence):\n",
    "    lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "    new_sentence = [lemmatizer.lemmatize(word, get_wordnet_pos(word) or wordnet.NOUN) for word in sentence]\n",
    "\n",
    "    return new_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.7 Spelling correction (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# Package may be used in this section\n",
    "import nltk\n",
    "from nltk.corpus import words\n",
    "from nltk.metrics.distance import jaccard_distance\n",
    "from nltk.util import ngrams\n",
    "\n",
    "# Spell correction is also important in text preprocessing.\n",
    "# Please refer to the Day2 slides and see how jaccard_distance works\n",
    "def spell_correction(sentence):\n",
    "    new_sentence = None\n",
    "    ##############################\n",
    "    # Your code here\n",
    "    ##############################\n",
    "    return new_sentence\n",
    "\n",
    "# example\n",
    "s = ['I', 'met', 'my', 'boy', 'frienss', 'yesterdsy']\n",
    "print(spell_correction(s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.8. Integrate all the functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_preprocessing(raw_sentence):\n",
    "    sentence = lower_casing(raw_sentence)\n",
    "    sentence = expand_abbriviation(sentence)\n",
    "    sentence = punctuation_removal(sentence)\n",
    "    sentence = tokenization(sentence)\n",
    "    sentence = stopword_removal(sentence)\n",
    "    sentence = lemmatization(sentence)\n",
    "#     sentence = spell_correction(sentence) # Spelling check\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Lets have a try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['eat', '100', 'hamburger', 'yesterdsy']\n"
     ]
    }
   ],
   "source": [
    "# A Common text pre-processing procedure is as follow:\n",
    "# Raw text -> Lower casing -> Expand abbr -> Punctuation removal->...\n",
    "# ... -> Tokenization  -> Stop word removal -> Lemmatization\n",
    "# All the functions are defined in above code blocks. Please feel free to go through it\n",
    "# and change some of the codes.\n",
    "\n",
    "# Let's assume we have a raw sentence.\n",
    "raw_sentence = 'He said, \"we\\'d have eaten more than 100 hamburgers from yesterdsy.\"'\n",
    "\n",
    "# Can you guess the result of procedure?\n",
    "sentence = text_preprocessing(raw_sentence)\n",
    "print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['eat', '100', 'hamburger', 'yesterdsy']\n"
     ]
    }
   ],
   "source": [
    "# Or if we only want to use some of the preprocessing techniques, we can call the function separately.\n",
    "sentence = lower_casing(raw_sentence)\n",
    "sentence = punctuation_removal(sentence)\n",
    "sentence = expand_abbriviation(sentence)\n",
    "sentence = tokenization(sentence)\n",
    "sentence = stopword_removal(sentence)\n",
    "sentence = lemmatization(sentence)\n",
    "# sentence = spell_correction(sentence) # Spelling check\n",
    "print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1 Hello\n",
      "1 []\n",
      "\n",
      "2 Hello, I am ASD knowledge bot. Feel free to ask me anything about autism spectrum disorder (ASD).\n",
      "2 ['asd', 'knowledge', 'bot', 'feel', 'free', 'autism', 'spectrum', 'disorder', 'asd']\n",
      "\n",
      "3 What is definition of Autistic Spectrum Disorder?\n",
      "3 ['definition', 'autistic', 'spectrum', 'disorder']\n",
      "\n",
      "4 Autism, or autism spectrum disorder (ASD), refers to a broad range of conditions characterized by challenges with social skills, repetitive behaviors, speech and nonverbal communication. According to the Centers for Disease Control, autism affects an estimated 1 in 54 children in the United States today.\n",
      "4 ['autism', 'autism', 'spectrum', 'disorder', 'asd', 'refers', 'broad', 'range', 'condition', 'characterize', 'challenge', 'social', 'skill', 'repetitive', 'behavior', 'speech', 'nonverbal', 'communication', 'center', 'disease', 'control', 'autism', 'estimate', '1', '54', 'child', 'united']\n",
      "\n",
      "5 What are the symptoms of Autistic Spectrum Disorder?\n",
      "5 ['symptom', 'autistic', 'spectrum', 'disorder']\n",
      "\n",
      "6 Making little or inconsistent eye contact. \n",
      "6 ['inconsistent', 'eye', 'contact']\n",
      "\n",
      "7 Tending not to look at or listen to people.\n",
      "7 ['tend', 'not', 'listen', 'people']\n",
      "\n",
      "8 Rarely sharing enjoyment of objects or activities by pointing or showing things to others.\n",
      "8 ['rarely', 'share', 'enjoyment', 'object', 'activity']\n",
      "\n",
      "9 Failing to, or being slow to, respond to someone calling their name or to other verbal attempts to gain attention.\n",
      "9 ['fail', 'slow', 'respond', 'call', 'verbal', 'attempt', 'gain', 'attention']\n",
      "\n",
      "10 Having difficulties with the back and forth of conversation.\n",
      "10 ['difficulty', 'conversation']\n",
      "\n",
      "11 Often talking at length about a favorite subject without noticing that others are not interested or without giving others a chance to respond.\n",
      "11 ['talk', 'length', 'favorite', 'subject', 'notice', 'not', 'chance', 'respond']\n",
      "\n",
      "12 Having facial expressions, movements, and gestures that do not match what is being said.\n",
      "12 ['facial', 'expression', 'movement', 'gesture', 'not', 'match']\n",
      "\n",
      "13 Having an unusual tone of voice that may sound sing-song or flat and robot-like.\n",
      "13 ['unusual', 'tone', 'voice', 'sound', 'singsong', 'flat', 'robotlike']\n",
      "\n",
      "14 Having trouble understanding another person鈥檚 point of view or being unable to predict or understand other people鈥檚 actions.\n",
      "14 ['trouble', 'understand', 'person鈥檚', 'view', 'unable', 'predict', 'understand', 'people鈥檚', 'action']\n",
      "\n",
      "15 Repeating certain behaviors or having unusual behaviors. For example, repeating words or phrases, a behavior called echolalia.\n",
      "15 ['repeat', 'behavior', 'unusual', 'behavior', 'repeat', 'phrase', 'behavior', 'call', 'echolalia']\n",
      "\n",
      "16 Having a lasting intense interest in certain topics, such as numbers, details, or facts.\n",
      "16 ['last', 'intense', 'topic', 'detail']\n",
      "\n",
      "17 Having overly focused interests, such as with moving objects or parts of objects.\n",
      "17 ['overly', 'focus', 'move', 'object', 'object']\n",
      "\n",
      "18 Getting upset by slight changes in a routine.\n",
      "18 ['upset', 'slight', 'routine']\n",
      "\n",
      "19 Being more or less sensitive than other people to sensory input, such as light, noise, clothing, or temperature.\n",
      "19 ['sensitive', 'people', 'sensory', 'input', 'light', 'noise', 'clothing', 'temperature']\n",
      "\n",
      "20 People with ASD may also experience sleep problems and irritability. Although people with ASD experience many challenges, they may also have many strengths, including:\n",
      "20 ['people', 'asd', 'experience', 'sleep', 'irritability', 'people', 'asd', 'experience', 'challenge', 'strength', 'include', ':']\n",
      "\n",
      "21 Being able to learn things in detail and remember information for long periods of time.\n",
      "21 ['learn', 'detail', 'remember', 'period', 'time']\n",
      "\n",
      "22 Being strong visual and auditory learners.\n",
      "22 ['strong', 'visual', 'auditory', 'learner']\n",
      "\n",
      "23 Excelling in math, science, music, or art.\n",
      "23 ['excel', 'math', 'science', 'music', 'art']\n",
      "\n",
      "24 What should I do if I got diagnosis the Autistic Spectrum Disorder?\n",
      "24 ['diagnosis', 'autistic', 'spectrum', 'disorder']\n",
      "\n",
      "25 Consult a doctor and psychologist for early intervention programs.\n",
      "25 ['consult', 'doctor', 'psychologist', 'intervention', 'program']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# In the workshop folder, we have a database called questionbase_raw.txt. Try to import the txt file\n",
    "# into the Python and do the preprocessing for all the sentence. See what will happen!\n",
    "\n",
    "with open('./questionbase_raw.txt') as file:\n",
    "    raw_sentences = [sentence.replace('\\n', '') for sentence in file.readlines()]\n",
    "\n",
    "i = 1\n",
    "for raw_sentence in raw_sentences:\n",
    "    processed_sentence = text_preprocessing(raw_sentence)\n",
    "    if raw_sentence != 'Q' and raw_sentence != 'A':\n",
    "        print(i, raw_sentence)\n",
    "        print(i, processed_sentence)\n",
    "        i += 1\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Text Preprocessing [Workshop]\n",
    "### Spacy (Python package) is modern and powerful NLP tool. \n",
    "### You can use spacy functions do most of the preprocessing work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "raw_sentence :  He said, \"we'd have eaten more than 100 hamburgers from yesterdsy.\"\n"
     ]
    }
   ],
   "source": [
    "# Create the nlp tool\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Raw sentence\n",
    "raw_sentence = 'He said, \"we\\'d have eaten more than 100 hamburgers from yesterdsy.\"'\n",
    "print(\"raw_sentence : \", raw_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "He -PRON- PRON PRP nsubj Xx True True\nsaid say VERB VBD ROOT xxxx True False\n, , PUNCT , punct , False False\n\" \" PUNCT `` punct \" False False\nwe -PRON- PRON PRP nsubj xx True True\n'd 'd VERB MD aux 'x False True\nhave have AUX VB aux xxxx True True\neaten eat VERB VBN ccomp xxxx True False\nmore more ADJ JJR amod xxxx True True\nthan than SCONJ IN quantmod xxxx True True\n100 100 NUM CD nummod ddd False False\nhamburgers hamburger NOUN NNS dobj xxxx True False\nfrom from ADP IN prep xxxx True True\nyesterdsy yesterdsy PROPN NNP pobj xxxx True False\n. . PUNCT . punct . False False\n\" \" PUNCT '' punct \" False False\n"
     ]
    }
   ],
   "source": [
    "# Use SpaCy nlp tool to process the raw sentence\n",
    "token_sentence = nlp(raw_sentence)\n",
    "for token in token_sentence:\n",
    "    print(token.text, token.lemma_, token.pos_, token.tag_, token.dep_,\n",
    "          token.shape_, token.is_alpha, token.is_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'He'"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "token_sentence[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'PRON'"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "token_sentence[0].pos_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your hands-on time now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used the given information to implement your own text preprocessing\n",
    "def my_preprocessing(raw_sentence, nlp_tool):\n",
    "    token_sentence = nlp_tool(raw_sentence)\n",
    "    preprocessed_sentence = None\n",
    "    \n",
    "    #########################\n",
    "    # Your code here\n",
    "    # You should ignore the abbreviation expanding part here since those abbr words\n",
    "    # are identified as stop words in spacy.\n",
    "    # \n",
    "    # But also consider how to process abbr like U.K. and US such words. \n",
    "    # (hint: word2vec, not mentioned in this course)\n",
    "    \n",
    "    preprocessed_sentence =[]\n",
    "    for token in token_sentence:\n",
    "        if token.lemma_=='-PRON-':\n",
    "            continue\n",
    "        elif token.pos_=='PUNCT':\n",
    "            continue\n",
    "        elif token.is_stop:\n",
    "            continue\n",
    "        else:\n",
    "            preprocessed_sentence.append(token.lemma_.lower())\n",
    "    \n",
    "    #########################\n",
    "\n",
    "    \n",
    "    return preprocessed_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1 Hello\n1 =>> text prep output:\n []\n1 =>> my spacy  output:\n ['hello']\n\n2 Hello, I am ASD knowledge bot. Feel free to ask me anything about autism spectrum disorder (ASD).\n2 =>> text prep output:\n ['asd', 'knowledge', 'bot', 'feel', 'free', 'autism', 'spectrum', 'disorder', 'asd']\n2 =>> my spacy  output:\n ['hello', 'asd', 'knowledge', 'bot', 'feel', 'free', 'ask', 'autism', 'spectrum', 'disorder', 'asd']\n\n3 What is definition of Autistic Spectrum Disorder?\n3 =>> text prep output:\n ['definition', 'autistic', 'spectrum', 'disorder']\n3 =>> my spacy  output:\n ['definition', 'autistic', 'spectrum', 'disorder']\n\n4 Autism, or autism spectrum disorder (ASD), refers to a broad range of conditions characterized by challenges with social skills, repetitive behaviors, speech and nonverbal communication. According to the Centers for Disease Control, autism affects an estimated 1 in 54 children in the United States today.\n4 =>> text prep output:\n ['autism', 'autism', 'spectrum', 'disorder', 'asd', 'refers', 'broad', 'range', 'condition', 'characterize', 'challenge', 'social', 'skill', 'repetitive', 'behavior', 'speech', 'nonverbal', 'communication', 'center', 'disease', 'control', 'autism', 'estimate', '1', '54', 'child', 'united']\n4 =>> my spacy  output:\n ['autism', 'autism', 'spectrum', 'disorder', 'asd', 'refer', 'broad', 'range', 'condition', 'characterize', 'challenge', 'social', 'skill', 'repetitive', 'behavior', 'speech', 'nonverbal', 'communication', 'accord', 'centers', 'disease', 'control', 'autism', 'affect', 'estimate', '1', '54', 'child', 'united', 'states', 'today']\n\n5 What are the symptoms of Autistic Spectrum Disorder?\n5 =>> text prep output:\n ['symptom', 'autistic', 'spectrum', 'disorder']\n5 =>> my spacy  output:\n ['symptom', 'autistic', 'spectrum', 'disorder']\n\n6 Making little or inconsistent eye contact. \n6 =>> text prep output:\n ['inconsistent', 'eye', 'contact']\n6 =>> my spacy  output:\n ['make', 'little', 'inconsistent', 'eye', 'contact']\n\n7 Tending not to look at or listen to people.\n7 =>> text prep output:\n ['tend', 'not', 'listen', 'people']\n7 =>> my spacy  output:\n ['tend', 'look', 'listen', 'people']\n\n8 Rarely sharing enjoyment of objects or activities by pointing or showing things to others.\n8 =>> text prep output:\n ['rarely', 'share', 'enjoyment', 'object', 'activity']\n8 =>> my spacy  output:\n ['rarely', 'share', 'enjoyment', 'object', 'activity', 'point', 'show', 'thing']\n\n9 Failing to, or being slow to, respond to someone calling their name or to other verbal attempts to gain attention.\n9 =>> text prep output:\n ['fail', 'slow', 'respond', 'call', 'verbal', 'attempt', 'gain', 'attention']\n9 =>> my spacy  output:\n ['fail', 'slow', 'respond', 'call', 'verbal', 'attempt', 'gain', 'attention']\n\n10 Having difficulties with the back and forth of conversation.\n10 =>> text prep output:\n ['difficulty', 'conversation']\n10 =>> my spacy  output:\n ['have', 'difficulty', 'forth', 'conversation']\n\n11 Often talking at length about a favorite subject without noticing that others are not interested or without giving others a chance to respond.\n11 =>> text prep output:\n ['talk', 'length', 'favorite', 'subject', 'notice', 'not', 'chance', 'respond']\n11 =>> my spacy  output:\n ['talk', 'length', 'favorite', 'subject', 'notice', 'interested', 'give', 'chance', 'respond']\n\n12 Having facial expressions, movements, and gestures that do not match what is being said.\n12 =>> text prep output:\n ['facial', 'expression', 'movement', 'gesture', 'not', 'match']\n12 =>> my spacy  output:\n ['have', 'facial', 'expression', 'movement', 'gesture', 'match', 'say']\n\n13 Having an unusual tone of voice that may sound sing-song or flat and robot-like.\n13 =>> text prep output:\n ['unusual', 'tone', 'voice', 'sound', 'singsong', 'flat', 'robotlike']\n13 =>> my spacy  output:\n ['have', 'unusual', 'tone', 'voice', 'sound', 'sing', 'song', 'flat', 'robot', 'like']\n\n14 Having trouble understanding another person鈥檚 point of view or being unable to predict or understand other people鈥檚 actions.\n14 =>> text prep output:\n ['trouble', 'understand', 'person鈥檚', 'view', 'unable', 'predict', 'understand', 'people鈥檚', 'action']\n14 =>> my spacy  output:\n ['have', 'trouble', 'understand', 'person鈥檚', 'point', 'view', 'unable', 'predict', 'understand', 'people鈥檚', 'action']\n\n15 Repeating certain behaviors or having unusual behaviors. For example, repeating words or phrases, a behavior called echolalia.\n15 =>> text prep output:\n ['repeat', 'behavior', 'unusual', 'behavior', 'repeat', 'phrase', 'behavior', 'call', 'echolalia']\n15 =>> my spacy  output:\n ['repeat', 'certain', 'behavior', 'have', 'unusual', 'behavior', 'example', 'repeat', 'word', 'phrase', 'behavior', 'call', 'echolalia']\n\n16 Having a lasting intense interest in certain topics, such as numbers, details, or facts.\n16 =>> text prep output:\n ['last', 'intense', 'topic', 'detail']\n16 =>> my spacy  output:\n ['have', 'last', 'intense', 'interest', 'certain', 'topic', 'number', 'detail', 'fact']\n\n17 Having overly focused interests, such as with moving objects or parts of objects.\n17 =>> text prep output:\n ['overly', 'focus', 'move', 'object', 'object']\n17 =>> my spacy  output:\n ['have', 'overly', 'focus', 'interest', 'move', 'object', 'part', 'object']\n\n18 Getting upset by slight changes in a routine.\n18 =>> text prep output:\n ['upset', 'slight', 'routine']\n18 =>> my spacy  output:\n ['get', 'upset', 'slight', 'change', 'routine']\n\n19 Being more or less sensitive than other people to sensory input, such as light, noise, clothing, or temperature.\n19 =>> text prep output:\n ['sensitive', 'people', 'sensory', 'input', 'light', 'noise', 'clothing', 'temperature']\n19 =>> my spacy  output:\n ['sensitive', 'people', 'sensory', 'input', 'light', 'noise', 'clothing', 'temperature']\n\n20 People with ASD may also experience sleep problems and irritability. Although people with ASD experience many challenges, they may also have many strengths, including:\n20 =>> text prep output:\n ['people', 'asd', 'experience', 'sleep', 'irritability', 'people', 'asd', 'experience', 'challenge', 'strength', 'include', ':']\n20 =>> my spacy  output:\n ['people', 'asd', 'experience', 'sleep', 'problem', 'irritability', 'people', 'asd', 'experience', 'challenge', 'strength', 'include']\n\n21 Being able to learn things in detail and remember information for long periods of time.\n21 =>> text prep output:\n ['learn', 'detail', 'remember', 'period', 'time']\n21 =>> my spacy  output:\n ['able', 'learn', 'thing', 'detail', 'remember', 'information', 'long', 'period', 'time']\n\n22 Being strong visual and auditory learners.\n22 =>> text prep output:\n ['strong', 'visual', 'auditory', 'learner']\n22 =>> my spacy  output:\n ['strong', 'visual', 'auditory', 'learner']\n\n23 Excelling in math, science, music, or art.\n23 =>> text prep output:\n ['excel', 'math', 'science', 'music', 'art']\n23 =>> my spacy  output:\n ['excel', 'math', 'science', 'music', 'art']\n\n24 What should I do if I got diagnosis the Autistic Spectrum Disorder?\n24 =>> text prep output:\n ['diagnosis', 'autistic', 'spectrum', 'disorder']\n24 =>> my spacy  output:\n ['get', 'diagnosis', 'autistic', 'spectrum', 'disorder']\n\n25 Consult a doctor and psychologist for early intervention programs.\n25 =>> text prep output:\n ['consult', 'doctor', 'psychologist', 'intervention', 'program']\n25 =>> my spacy  output:\n ['consult', 'doctor', 'psychologist', 'early', 'intervention', 'program']\n\n"
     ]
    }
   ],
   "source": [
    "# Similarly, call my_preprocessing to process all the text data and\n",
    "# see what's the difference between the two functions\n",
    "\n",
    "with open('./questionbase_raw.txt') as file:\n",
    "    raw_sentences = [sentence.replace('\\n', '') for sentence in file.readlines()]\n",
    "    preprocessed_sentences = None # result from 'my_preprocessing'\n",
    "    given_preprocessed_sentences = None # result by running the 'text_preprocessing'\n",
    "    \n",
    "    #########################\n",
    "    # Your code here\n",
    "    nlp_tool = spacy.load('en_core_web_sm')\n",
    "    preprocessed_sentences = []\n",
    "    given_preprocessed_sentences= []\n",
    "\n",
    "    for raw_sentence in raw_sentences:\n",
    "        if raw_sentence == 'Q' or raw_sentence == 'A':\n",
    "            continue\n",
    "        else:\n",
    "            preprocessed_sentences.append(text_preprocessing(raw_sentence))\n",
    "            given_preprocessed_sentences.append(my_preprocessing(raw_sentence, nlp_tool))\n",
    "    #########################\n",
    "    \n",
    "    \n",
    "    \n",
    "    i = 1\n",
    "    for raw_sentence in raw_sentences:\n",
    "        if raw_sentence == 'Q' or raw_sentence == 'A':\n",
    "            continue\n",
    "        else:\n",
    "            print(i, raw_sentence)\n",
    "            print(i, '=>> text prep output:\\n', preprocessed_sentences[i-1])\n",
    "            print(i, '=>> my spacy  output:\\n', given_preprocessed_sentences[i-1])\n",
    "            i += 1\n",
    "            print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the two results and explain which one is better and why?\n",
    "# Provide your answer here\n",
    "# 1. lower casing ： both of the methods do well on this part as python already support this function\n",
    "# 2. Punctuation removal : spaCy dose better than the function in text_preprocessing, because the function punctuation_removal is built by a customized punctuation set which might not contains all punctuation\n",
    "# 3. Expand abbreviation: both of them do well in this case, but spaCy might be better when processing large amounts of text data, beacause function expand_abbriviation only defined abbreviation for this case.\n",
    "# 4. Tokenization: both of them are doing well.\n",
    "# 5. Stop word removal: both of them are doing well, but spaCy might be better for processing large data as we need to manually update the stopwords dataset.\n",
    "# 6. Lemmatization: both are doing well.\n",
    "# Summary : When processing the text data in a certain area which has a strong demand on customization, the 1st method (text_preprocessing) might be better. When processing massive data without strong demand on customization, we can use the 2nd method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "`The end is called a new start.` --- ISS: **I** **S**(elf) **S**(tudy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.1 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "2eaef376103c3017a649a3feef589e184426c8e03bf4143e9db4c604a121b0df"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}